[latent_redq]

algorithm = 'latent_redq'

device = T.device('cuda:0')
seed = 0

env_name = 'cheetah'
task_name = 'run'

time_steps = 2000000

buffer_size = 100000
batch_size_sac = 256
batch_size_latent = 32

gamma = 0.99
tau = 5e-3

actor_lr = 3e-4
critic_lr = 3e-4
alpha_lr = 3e-4
latent_lr = 1e-4

z1_dim = 32
z2_dim = 256
feature_dim = 256
num_sequences = 8
hidden_units = (256, 256)

policy_update_delay = 20
target_entropy = 'auto'
delay_update_steps = 'auto'
q_target_mode = 'min'

utd_ratio = 20
num_Q = 10
num_min = 2

initial_collection_steps = 10000
initial_learning_steps = 100000
action_repeat = 4

evaluate_episodes = 5
evaluate_rate = 10000
evaluate = False

save_dir = './model'
file_critic = 'REDQ_critic.pth'